# CCG-MCP 配置文件示例
# 请复制此文件到 ~/.ccg-mcp/config.toml 并填入你的配置

[coder]
# Coder 工具可配置任意支持 Claude Code API 的模型后端
# 推荐使用 GLM-4.7 作为参考案例，也可选用其他模型（如 Minimax、DeepSeek 等）

# API 认证（必填）
# GLM 示例：从智谱 AI 平台获取 https://open.bigmodel.cn
api_token = "your-api-token"

# API 地址（必填，需支持 Claude Code API 协议）
# GLM 示例：
base_url = "https://open.bigmodel.cn/api/anthropic"

# 模型名称（可选，默认 gpt-5.2-codex）
model = "glm-4.7"

# 额外环境变量（建议保留）
# 可以添加任何需要传递给 Claude CLI 的环境变量
[coder.env]
# 禁用非必要的网络流量（遥测等），建议保持开启
CLAUDE_CODE_DISABLE_NONESSENTIAL_TRAFFIC = "1"

# Codex 配置（可选）
# Codex 工具默认使用 codex CLI 自己的配置
# 如需覆盖默认模型，可在此指定
[codex]
model = "gpt-5.2-codex"  # 可选，默认 gpt-5.2-codex

# Gemini 配置（可选）
# Gemini 工具默认使用 gemini-3-pro-preview
# 如需覆盖默认模型，可在此指定
[gemini]
model = "gemini-3-pro-preview"  # 可选，默认 gemini-3-pro-preview
